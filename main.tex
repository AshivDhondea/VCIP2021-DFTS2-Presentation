\PassOptionsToPackage{dvipsnames}{xcolor}
\documentclass[aspectratio=169]{beamer}

\mode<presentation> {

\usetheme{Montpellier} 
\usecolortheme{beaver}

\setbeamertemplate{footline}[page number] 
\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\setbeamertemplate{caption}[numbered]
\setbeamerfont{caption}{size=\scriptsize}
%\usepackage{etex}
\usepackage{array} 
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usefonttheme{professionalfonts}
\usepackage{mathptmx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{float}
% ------------------ My own stuff
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath,amsthm,amssymb}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\R}{\mathbb{R}}

\beamertemplatenavigationsymbolsempty

\usepackage{rotating}
\usepackage{tikz}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{verbatim}

\newcommand\blfootnote[1]{%
	\begingroup
	\renewcommand\thefootnote{}\footnote{#1}%
	\addtocounter{footnote}{-1}%
	\endgroup
}


%------------------
%	TITLE PAGE
%------------------

\title[DFTS2 for CI]{DFTS2: Deep Feature Transmission Simulation
\\ for \\ Collaborative Intelligence}
\subtitle{\small VCIP 2021. Paper ID: xxxx} 

\author[Hans]{Ashiv Dhondea, Robert A. Cohen and Ivan V. {Bajić}}% Your name
\institute[SFU-Multimedia Lab] 
{
\small
Multimedia Lab\\School of Engineering Science\\Simon Fraser University \\ % Your institution for the title page
\smallskip
\centering
\includegraphics[scale=0.25]{SFUhorizontallogorgb.pdf}
}

\date{\today} % Date, can be changed to a custom date

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

\section{Collaborative Intelligence}
\begin{frame}
	\frametitle{Introduction: Collaborative Intelligence}
		\begin{figure}
		\begin{minipage}{.48\textwidth}
			\includegraphics[width=\linewidth]{image--000.png}
			\caption{Blueprint for Collaborative Intelligence. \cite{neurosurgeon}}
		\end{minipage}\hfill
		\begin{minipage}{.48\textwidth}
		\begin{itemize}
		    \item Collaborative Intelligence (CI) leverages edge-based \& cloud-based resources to bring ``AI to the edge". 
		    \item CI has shown promising potential for latency and energy savings compared to purely cloud-based or edge-based analysis solutions \cite{neurosurgeon,jointdnn}.
		\end{itemize}
		\end{minipage}
		\blfootnote{\tiny \textsuperscript{1} Y. Kang, J. Hauswald, C. Gao, A. Rovinski, T. Mudge, J. Mars, and L. Tang, “Neurosurgeon: Collaborative intelligence between the cloud and mobile edge,” SIGARCH Comput. Archit. News, vol. 45, p. 615–629, Apr. 2017.}
		\blfootnote{\tiny \textsuperscript{2} A. E. Eshratifar, M. S. Abrishami, and M. Pedram, “JointDNN: An efficient training and inference engine for intelligent mobile cloud computing services,” IEEE Trans. Mobile Computing, vol. 20, no. 2, pp. 565–576, Feb. 2021.}
	\end{figure}
\end{frame}

\begin{frame}
    	\frametitle{System overview: collaborative intelligence.}
	\begin{figure}[H]
		\centering
		\includegraphics[scale=0.33,viewport=2.391047 126.719996 531.251984 538.217984,clip]{systemoverviewtv3.pdf}
		\caption{Deep feature tensor transmission overview (adapted from \cite[Fig. 1]{cohen2021lightweight})\blfootnote{\tiny \textsuperscript{3} R. A. Cohen, H. Choi, and I. V. Bajić, “Lightweight compression of intermediate neural network features for collaborative intelligence,” IEEE Open Journal of Circuits and Systems, vol. 2, pp. 350–362, 2021.}}
	\end{figure}
\end{frame}

\section{Literature review}

\begin{frame}
\frametitle{Intermediate tensor transmission over communication channels}
	\begin{itemize}
	\item Deep Feature Transmission Simulator (DFTS) was developed to simulate packet-based transmission of deep features over unreliable communication channels \blfootnote{\tiny \textsuperscript{4} H. Unnibhavi, H. Choi, S. R. Alvar, and I. V. Bajić, “Dfts: Deep feature transmission simulator,” 2018.} \cite{unnibhavi2018dfts}.
		\item DFTS2 TensorFlow version 2, additional channel models, packet loss concealment methods, additional simulation modes.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Packet loss concealment}
	\begin{itemize}
		\item General tensor completion methods, such as SiLRTC (Simple Low Rank Tensor Completion) and HaLRTC (High accuracy Low Rank Tensor Completion) \cite{liu2012tensor}\blfootnote{\tiny \textsuperscript{5} J. Liu, P. Musialski, P. Wonka, and J. Ye,``Tensor completion for estimating missing values in visual data,” IEEE transactions on pattern analysis and machine intelligence, vol. 35, no. 1, pp. 208–220, 2012.}.
		\item Method tailored for intermediate feature tensors: ALTeC - Adaptive Linear Tensor Completion \cite{Bragile2020} \blfootnote{\tiny \textsuperscript{6} L. Bragilevsky and I. V.Bajić,``Tensor completion methods for collaborative intelligence,” IEEE Access, vol. 8, pp. 41162–41174, 2020.}
		%\item Image inpainting methods such as Navier-Stokes based inpainting \cite{navierstokes} \blfootnote{\tiny \textsuperscript{6} M. Bertalmio, A. L. Bertozzi, and G. Sapiro, ``Navier-Stokes, fluid dynamics, and image and video inpainting,” in Proc. IEEE/CVF CVPR, vol. 1, pp. I–355–I–362, 2001.}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Gilbert-Elliott (GE) communication channel model}
		\begin{figure}
		\begin{minipage}{.37\textwidth}
			\includegraphics[width=0.77\linewidth]{tileddamagedgridm.jpg}
			\caption{Corrupted ResNet-18 deep feature tensor.}
		\end{minipage}\hfill
		\begin{minipage}{.6\textwidth}
		\small Two-state Markov model with a good (G) state and a bad (B) state. Parameters: burst loss probability ($P_B$) \& average burst length ($B_L$).
			\begin{align}
p_{B\to G} & = \frac{1}{L_B} & p_{B\to B} & =1-p_{B\to G} \label{eq:ge:1}
\end{align}
\begin{align}
p_{G\to B} & = \frac{P_B}{L_B(1-P_B)} & p_{G\to G} & = 1-p_{G\to B} \label{eq:ge:2}
\end{align}
\small 	The Gilbert-Elliott model has been shown to fittingly \mbox{capture} real-time observed packet loss patterns over the \mbox{Internet}. \cite{5755057}
		\end{minipage}
		\blfootnote{\tiny \textsuperscript{7} G. Hasslinger and O. Hohlfeld, “The gilbert-elliott model for packet loss in real time services on the internet,” in 14th GI/ITG Conference - Measurement, Modelling and Evaluation of Computer and Communication Systems, pp. 1–15, 2008.} 
	\end{figure}
\end{frame}

\section{Preliminaries}
\begin{frame}
	\frametitle{A deep feature tensor}
	\begin{figure}[H]
		\centering\includegraphics[scale=0.9]{tensorlostviz3icip.pdf}
		\caption{Tensor $\mathcal{X}$ from layer add\_1 of ResNet-18. Several consecutive rows in each channel form a feature data packet.}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Quantizing deep feature tensors}
	\begin{block}{Quantization to $n$-bits}
		For each feature tensor element $x \in \mathcal{X}$
		\[
		x_{\text{quant}} = \Bigg \lfloor \frac{(x - \mathcal{X}_{\text{min}})}{( \mathcal{X}_{\text{max}} -  \mathcal{X}_{\text{min}})} \cdot 2^{n-1} \Bigg \rceil
		\]
		Feature tensors can be cast from 32-bit floats to unsigned 8-bit integers.
	\end{block}
\end{frame}

\begin{frame}
	\frametitle{Corrupted tensor visualization}
	\begin{figure}
		\begin{minipage}{.4\textwidth}
			\includegraphics[width=0.75\linewidth]{tensorviz4.pdf}
			\caption{Corrupted ResNet-18 deep feature tensor consisting of 64 channels. Each channel consists of 7 packets. Packets are $8 \times 56$ blocks of deep feature tensor values.}
		\end{minipage}\hfill
		\begin{minipage}{.4\textwidth}
			\includegraphics[width=0.78\linewidth]{tiledgridtensor.jpg}
			\caption{Tiled tensor $\tilde{\mathcal{X}} \in \mathbb{R}^{56 \times 56 \times 64}$ visualization. Each tile represents a channel of shape $56 \times 56$. }
		\end{minipage}
	\end{figure}
\end{frame}

\section{Conclusions}
\begin{frame}
	\frametitle{Conclusions and recommendations}
	\begin{itemize}
		\item CALTeC exploits intra- and inter-channel similarity in deep feature tensors to find the best candidates in other channels to fill in the gaps in corrupted packetized deep feature tensors.
		\item CALTeC adjusts the recovered data with an affine transformation.
		\item CALTeC is slower than ALTeC but unlike ALTeC, it does not require pre-training.
		\item Both ALTeC and CALTeC are much faster than SiLRTC and HaLRTC.
		\item Future work can focus on extending DFTS to run different tasks and to incorporate different compression methods for the transmitted deep feature tensor.
	\end{itemize}
\end{frame}

%------------------------------------------------
\section{Implementation}
\begin{frame}
\frametitle{Implementation \& Results}
Public repository for DFTS2: \url{https://github.com/AshivDhondea/DFTS_TF2}.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{frame.pdf}
\end{figure}

This repository also contains the packet loss traces and Monte Carlo experiment results presented in this paper.
	\end{frame}
	
%---------------------------------------------
\section{References}
\bibliographystyle{ieeetr}
\bibliography{icipcaltecrefs}
%-----------------------------------------------
\end{document} 